from pyalgo import *

# --- New imports for indicator computation and persistence ---
from pathlib import Path
import pandas as pd
import numpy as np
from collections import deque  # æ–°å¢žï¼šçŽ¯å½¢ç¼“å†²é˜Ÿåˆ—


class Demo:
    """Subscribe klines and compute/store a correlation-based factor.

    Indicator definition (streaming):
    - Maintain 1m OHLCV series
    - Rolling mean/std use min_periods=100 for both close and volume
    - Clip close and volume by their rolling mean Â± 0.5 * std (window=1200)
    - Rolling correlation of clipped close vs clipped volume (window=1200, min_periods=200)
    - Then reindex corr series to 5-minute grid and compute:
      fast EMA(span=48), slow EMA(span=8*48),
      zscore = (fast - slow) / rolling_std(window=8*48, min_periods=10)
    Persist latest columns to disk per symbol-stream.
    """

    def __init__(self, depth: DepthSubscription, kline: BarSubscription):
        self.depth = depth
        self.kline = kline

        # set callback
        self.depth.on_data = self.on_depth
        self.kline.on_data = self.on_kline

        # ä½¿ç”¨çŽ¯å½¢ç¼“å†²ï¼Œä»…ä¿ç•™æœ€è¿‘ N åˆ†é’Ÿæ•°æ®ï¼ˆè¦†ç›–æœ€å¤§çª—å£ 1200ï¼Œå¹¶ç•™å°‘é‡å†—ä½™ï¼‰
        self.keep_window = 1300
        self.buf = deque(maxlen=self.keep_window)  # æ¯ä¸ªå…ƒç´ ä¸º dictï¼š{"ts", "o","h","l","c","vol","amount"}

        # å½“å‰åˆ†é’Ÿçš„ä¸´æ—¶å¿«ç…§ï¼ˆåŒä¸€åˆ†é’Ÿå†…è¦†ç›–æ›´æ–°ï¼›åˆ†é’Ÿåˆ‡æ¢æ—¶æŽ¨å…¥ bufï¼‰
        self.cur_ts = None
        self.cur_row = None
        
        # Track last processed minute to avoid duplicates
        self.last_minute = None

        # parameters (align with user's notebook)
        self.window = 1200  # 1200 minutes = 20 hours
        self.min_mean = 100
        self.min_corr = 200
        self.norm_window = 48

        # prepare output path lazily (need stream from first kline event)
        self.out_dir = Path("log/indicators")
        self.out_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¨‹åºå¯åŠ¨æ—¶æ¸…ç†æ—§çš„è¾“å‡ºæ–‡ä»¶
        print("ðŸ§¹ æ¸…ç†æ—§çš„å› å­æ–‡ä»¶...")
        for old_file in self.out_dir.glob("*_factor.csv"):
            try:
                old_file.unlink()
                print(f"   åˆ é™¤: {old_file.name}")
            except FileNotFoundError:
                pass  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿½ç•¥
        for old_file in self.out_dir.glob("*_factor.parquet"):
            try:
                old_file.unlink()
                print(f"   åˆ é™¤: {old_file.name}")
            except FileNotFoundError:
                pass  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿½ç•¥
        print("âœ… æ¸…ç†å®Œæˆï¼Œå‡†å¤‡å¼€å§‹æ–°çš„å› å­è®¡ç®—")
        
        self._out_parquet = None
        self._out_csv = None
        self._out_csv_5m = None
        self._last_5m_ts = None

    # ----------------- callbacks -----------------
    def on_kline(self, kline: Kline):
        # lazily derive output filenames using kline.stream on first data
        if self._out_parquet is None or self._out_csv is None:
            symbol_stream = kline.stream if hasattr(kline, "stream") else f"{kline.symbol}@kline"
            fname = symbol_stream.replace("@", "_").replace(":", "")
            self._out_parquet = self.out_dir / f"{fname}_factor.parquet"
            self._out_csv = self.out_dir / f"{fname}_factor.csv"
            self._out_csv_5m = self.out_dir / f"{fname}_factor_5m.csv"

        # Convert timestamp to minute-level precision
        timestamp_ms = int(kline.time)
        minute_timestamp = (timestamp_ms // 60000) * 60000  # Round down to minute
        current_minute = pd.to_datetime(minute_timestamp, unit="ms")
        
        # ç¬¬ä¸€æ¬¡åˆå§‹åŒ–å½“å‰åˆ†é’Ÿ
        if self.cur_ts is None:
            self.cur_ts = current_minute
            self.cur_row = {
                "ts": current_minute,
                "o": kline.open,
                "h": kline.high,
                "l": kline.low,
                "c": kline.close,
                "vol": kline.volume,
                "amount": kline.amount,
            }
            print(f"ðŸ“Š New minute data: {current_minute} | Close: {kline.close} | Buffer: {len(self.buf)}")
            return

        # æ–°åˆ†é’Ÿå¼€å§‹ï¼šå…ˆç»“ç®—ä¸Šä¸€åˆ†é’Ÿï¼ˆå·²æ”¶ç›˜ï¼‰ï¼Œå†å¼€å¯æ–°åˆ†é’Ÿ
        if current_minute > self.cur_ts:
            # æŠŠä¸Šä¸€åˆ†é’Ÿæœ€ç»ˆå¿«ç…§æŽ¨å…¥çŽ¯å½¢ç¼“å†²
            self.buf.append(self.cur_row)

            # è®¡ç®—æŒ‡æ ‡ï¼ˆå½“ç¼“å†²é•¿åº¦æ»¡è¶³æœ€å°çª—å£ï¼‰
            if len(self.buf) >= max(self.min_corr, self.min_mean):
                self._compute_indicator()  # ä»Ž buf æž„å»º df å¹¶è®¡ç®— pv_corr/zscore ç­‰
                if hasattr(self, 'df') and "zscore" in self.df.columns:
                    last = self.df.iloc[-1]
                    print(
                        f"ðŸ“ˆ {self.cur_ts} | close={last.get('c')} | pv_corr={round(last.get('pv_corr', np.nan), 4)} | z={round(last.get('zscore', np.nan), 4)}"
                    )

            # æŒä¹…åŒ–ä¸Šä¸€åˆ†é’Ÿï¼ˆåªè¿½åŠ ä¸€è¡Œï¼‰
            self._persist()

            # å¼€å¯æ–°åˆ†é’Ÿå¿«ç…§ï¼ˆåŒä¸€åˆ†é’Ÿå†…ä»…è¦†ç›–ï¼Œä¸è½ç›˜ä¸è®¡ç®—ï¼‰
            self.cur_ts = current_minute
            self.cur_row = {
                "ts": current_minute,
                "o": kline.open,
                "h": kline.high,
                "l": kline.low,
                "c": kline.close,
                "vol": kline.volume,
                "amount": kline.amount,
            }
            print(f"ðŸ“Š New minute data: {current_minute} | Close: {kline.close} | Buffer: {len(self.buf)}")
        else:
            # åŒä¸€åˆ†é’Ÿå†…ï¼šåªè¦†ç›–ä¸ºæœ€æ–°å¿«ç…§ï¼ˆäº¤æ˜“æ‰€é€ç§’ kline çš„æœ€æ–°å€¼ï¼‰
            self.cur_row.update({
                "h": kline.high,
                "l": kline.low,
                "c": kline.close,
                "vol": kline.volume,
                "amount": kline.amount,
            })
            print(f"ðŸ”„ Update: {current_minute} | Close: {kline.close}")

    def on_depth(self, depth: Depth):
        # keep the original simple print for depth
        print(f"ðŸ“Š Depth: {depth.datetime} {depth.symbol}")

    # ----------------- core logic -----------------
    def _build_df_from_buf(self):
        """å°†çŽ¯å½¢ç¼“å†²çš„æ•°æ®æž„å»ºä¸º DataFrameï¼ˆä»…ç”¨äºŽè®¡ç®—/æŒä¹…åŒ–æ—¶çš„ä¸´æ—¶è§†å›¾ï¼‰"""
        if not self.buf:
            return pd.DataFrame()
        df = pd.DataFrame(list(self.buf))
        df = df.set_index("ts")
        return df

    def _compute_indicator(self):
        # ä»ŽçŽ¯å½¢ç¼“å†²æž„å»ºä¸´æ—¶ df
        self.df = self._build_df_from_buf()
        if self.df.empty:
            return

        close = self.df["c"].astype(float)
        # Prefer quote volume (amount) if available to match offline factor using volCcyQuote
        volume = (
            self.df["amount"].astype(float)
            if "amount" in self.df.columns
            else self.df["vol"].astype(float)
        )

        # rolling stats with explicit min_periods to match notebook
        c_mean = close.rolling(self.window, min_periods=self.min_mean).mean()
        c_std = close.rolling(self.window, min_periods=self.min_mean).std()
        v_mean = volume.rolling(self.window, min_periods=self.min_mean).mean()
        v_std = volume.rolling(self.window, min_periods=self.min_mean).std()

        c_upper = c_mean + 0.5 * c_std
        c_lower = c_mean - 0.5 * c_std
        v_upper = v_mean + 0.5 * v_std
        v_lower = v_mean - 0.5 * v_std

        clip_c = close.clip(lower=c_lower, upper=c_upper)
        clip_v = volume.clip(lower=v_lower, upper=v_upper)

        pv_corr_1m = clip_c.rolling(self.window, min_periods=self.min_corr).corr(clip_v)
        self.df["pv_corr"] = pv_corr_1m

        # 5-minute normalization (align with notebook)
        index_5m = close.resample("5min").last().dropna().index
        factor_5m = pv_corr_1m.reindex(index_5m)

        # STRICT per user's formula: use ewm(norm_window) positional arg (com)
        fast_ema = factor_5m.ewm(self.norm_window, min_periods=10).mean()
        slow_ema = factor_5m.ewm(8 * self.norm_window, min_periods=10).mean()
        slow_std = factor_5m.rolling(8 * self.norm_window, min_periods=10).std()

        # z = (fast - slow) / slow_std
        z = (fast_ema - slow_ema) / slow_std.replace(0, np.nan)

        # Store 5m dataframe for persistence/inspection
        self.df5 = pd.DataFrame(
            {
                "pv_corr": factor_5m,
                "fast_ema": fast_ema,
                "slow_ema": slow_ema,
                "slow_std": slow_std,
                "zscore": z,
            },
            index=index_5m,
        )

    def _persist(self):
        # ä¼˜å…ˆä½¿ç”¨å·²è®¡ç®—å¥½çš„ dfï¼›å¦‚æžœå°šæœªè¾¾åˆ°æœ€å°çª—å£ï¼Œåˆ™ç”¨çŽ¯å½¢ç¼“å†²æž„å»º dfï¼ˆä»… OHLCVï¼‰
        df = getattr(self, "df", None)
        if df is None or df.empty or (df.index[-1] if not df.empty else None) != (self.buf[-1]["ts"] if self.buf else None):
            df = self._build_df_from_buf()
        if df.empty:
            return

        # åªæŒä¹…åŒ–"ä¸Šä¸€åˆ†é’Ÿï¼ˆçŽ¯å½¢ç¼“å†²æœ€åŽä¸€è¡Œï¼‰"
        last_row = df.iloc[[-1]].copy()
        last_row.index.name = "ts"

        desired_cols = [
            "o", "h", "l", "c", "vol", "amount",
            "pv_corr", "fast_ema", "slow_ema", "slow_std", "zscore",
        ]
        out_cols = [c for c in desired_cols if c in last_row.columns]
        last_row = last_row[out_cols]

        # é‡‡ç”¨ CSV è¿½åŠ å†™å…¥ï¼Œä¿ç•™å…¨åŽ†å²ä¸”ä¸å ç”¨è¿‡å¤šå†…å­˜ï¼›é¦–æ¬¡å†™å…¥å¸¦è¡¨å¤´
        if self._out_csv is not None:
            header = not self._out_csv.exists()
            last_row.to_csv(self._out_csv, mode="a", header=header)

        # é™„åŠ ï¼š5m ç»“æžœæŒä¹…åŒ–ï¼Œä»…åœ¨äº§ç”Ÿæ–°5måˆ»åº¦æ—¶è¿½åŠ ä¸€è¡Œ
        df5 = getattr(self, "df5", None)
        if df5 is not None and not df5.empty and self._out_csv_5m is not None:
            # å–æœ€åŽä¸€ä¸ªéžNaNçš„ zscore ç‚¹
            non_na = df5[~df5["zscore"].isna()]
            if not non_na.empty:
                last_5m_ts = non_na.index[-1]
                if self._last_5m_ts is None or last_5m_ts > self._last_5m_ts:
                    out_row_5m = non_na.iloc[[-1]].copy()
                    out_row_5m.index.name = "ts"
                    header5 = not self._out_csv_5m.exists()
                    out_row_5m.to_csv(self._out_csv_5m, mode="a", header=header5)
                    self._last_5m_ts = last_5m_ts


if __name__ == "__main__":
    eng = Engine(0.001)
    session = eng.make_session(
        addr="ws://localhost:8111", session_id=1, name="test", trading=True
    )

    depth = session.subscribe("dogeusdt", "depth")
    kline = session.subscribe("btcusdt", "kline:1m")
    demo = Demo(depth, kline)
    eng.run()
