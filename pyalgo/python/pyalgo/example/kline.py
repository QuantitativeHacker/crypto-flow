from pyalgo import *

# --- New imports for indicator computation and persistence ---
from pathlib import Path
import pandas as pd
import numpy as np
from collections import deque  # æ–°å¢žï¼šçŽ¯å½¢ç¼“å†²é˜Ÿåˆ—


class Demo:
    """Subscribe klines and compute/store a correlation-based factor.

    Indicator definition (streaming):
    - Maintain 1m OHLCV series
    - Rolling mean/std use min_periods=100 for both close and volume
    - Clip close and volume by their rolling mean Â± 0.5 * std (window=1200)
    - Rolling correlation of clipped close vs clipped volume (window=1200, min_periods=200)
    - Then reindex corr series to 5-minute grid and compute:
      fast EMA(span=48), slow EMA(span=8*48),
      zscore = (fast - slow) / rolling_std(window=8*48, min_periods=10)
    Persist latest columns to disk per symbol-stream.
    """

    def __init__(self, depth: DepthSubscription, kline: BarSubscription):
        self.depth = depth
        self.kline = kline

        # set callback
        self.depth.on_data = self.on_depth
        self.kline.on_data = self.on_kline

        # ä½¿ç”¨çŽ¯å½¢ç¼“å†²ï¼Œä»…ä¿ç•™æœ€è¿‘ N åˆ†é’Ÿæ•°æ®ï¼ˆè¦†ç›–æœ€å¤§çª—å£ 1200ï¼Œå¹¶ç•™å°‘é‡å†—ä½™ï¼‰
        self.keep_window = 1300
        self.buf = deque(maxlen=self.keep_window)  # æ¯ä¸ªå…ƒç´ ä¸º dictï¼š{"ts", "o","h","l","c","vol","amount"}

        # parameters (align with user's notebook)
        self.window = 1200  # 1200 minutes = 20 hours
        self.min_mean = 100
        self.min_corr = 200
        self.norm_window = 48

        # prepare output path lazily (need stream from first kline event)
        self.out_dir = Path("log/indicators")
        self.out_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¨‹åºå¯åŠ¨æ—¶æ¸…ç†æ—§çš„è¾“å‡ºæ–‡ä»¶
        print("ðŸ§¹ æ¸…ç†æ—§çš„å› å­æ–‡ä»¶...")
        for old_file in self.out_dir.glob("*_factor.csv"):
            try:
                old_file.unlink()
                print(f"   åˆ é™¤: {old_file.name}")
            except FileNotFoundError:
                pass  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿½ç•¥
        for old_file in self.out_dir.glob("*_factor.parquet"):
            try:
                old_file.unlink()
                print(f"   åˆ é™¤: {old_file.name}")
            except FileNotFoundError:
                pass  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿½ç•¥
        print("âœ… æ¸…ç†å®Œæˆï¼Œå‡†å¤‡å¼€å§‹æ–°çš„å› å­è®¡ç®—")
        
        self._out_parquet = None
        self._out_csv = None
        self._out_csv_5m = None
        self._last_5m_ts = None

    # ----------------- callbacks -----------------
    def on_kline(self, kline: Kline):
        # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶åï¼ˆé¦–æ¬¡è°ƒç”¨ï¼‰
        if self._out_csv is None:
            fname = kline.stream.replace("@", "_").replace(":", "")
            self._out_parquet = self.out_dir / f"{fname}_factor.parquet"
            self._out_csv = self.out_dir / f"{fname}_factor.csv"
            self._out_csv_5m = self.out_dir / f"{fname}_factor_5m.csv"

        # è®¡ç®—åˆ†é’Ÿçº§æ—¶é—´æˆ³
        current_minute = pd.to_datetime((kline.time // 60000) * 60000, unit="ms")
        
        # æž„å»ºçŠ¶æ€ä¿¡æ¯
        status = "ðŸŸ¢CLOSED" if kline.is_closed else "ðŸ”µLIVE"
        buy_pct = f" | Buy%: {kline.buy_volume/kline.volume*100:.1f}%" if kline.volume > 0 else ""
        info = f" | Trades: {kline.trade_count}{buy_pct}"
        
        if kline.is_closed:
            # Kçº¿å®Œç»“ï¼šå¤„ç† â†’ è®¡ç®— â†’ ä¿å­˜
            self.buf.append({
                "ts": current_minute, "o": kline.open, "h": kline.high, 
                "l": kline.low, "c": kline.close, "vol": kline.volume, "amount": kline.amount
            })
            
            # è®¡ç®—æŒ‡æ ‡å¹¶è¾“å‡ºä¿¡å·
            if len(self.buf) >= max(self.min_corr, self.min_mean):
                self._compute_indicator()
                if hasattr(self, 'df') and "zscore" in self.df.columns:
                    last = self.df.iloc[-1]
                    print(f"ðŸ“ˆ SIGNAL: {current_minute} | close={last.get('c')} | "
                          f"pv_corr={last.get('pv_corr', np.nan):.4f} | z={last.get('zscore', np.nan):.4f}")
            
            self._persist()
            print(f"ðŸ“Š {status} {current_minute} | Close: {kline.close}{info}")
        else:
            # å®žæ—¶æ›´æ–°ï¼šä»…æ˜¾ç¤º
            print(f"ðŸ”„ {status} {current_minute} | Close: {kline.close}{info}")

    def on_depth(self, depth: Depth):
        # keep the original simple print for depth
        print(f"ðŸ“Š Depth: {depth.datetime} {depth.symbol}")

    # ----------------- core logic -----------------
    def _build_df_from_buf(self):
        """å°†çŽ¯å½¢ç¼“å†²çš„æ•°æ®æž„å»ºä¸º DataFrameï¼ˆä»…ç”¨äºŽè®¡ç®—/æŒä¹…åŒ–æ—¶çš„ä¸´æ—¶è§†å›¾ï¼‰"""
        if not self.buf:
            return pd.DataFrame()
        df = pd.DataFrame(list(self.buf))
        df = df.set_index("ts")
        return df

    def _compute_indicator(self):
        # ä»ŽçŽ¯å½¢ç¼“å†²æž„å»ºä¸´æ—¶ df
        self.df = self._build_df_from_buf()
        if self.df.empty:
            return

        close = self.df["c"].astype(float)
        # Prefer quote volume (amount) if available to match offline factor using volCcyQuote
        volume = (
            self.df["amount"].astype(float)
            if "amount" in self.df.columns
            else self.df["vol"].astype(float)
        )

        # rolling stats with explicit min_periods to match notebook
        c_mean = close.rolling(self.window, min_periods=self.min_mean).mean()
        c_std = close.rolling(self.window, min_periods=self.min_mean).std()
        v_mean = volume.rolling(self.window, min_periods=self.min_mean).mean()
        v_std = volume.rolling(self.window, min_periods=self.min_mean).std()

        c_upper = c_mean + 0.5 * c_std
        c_lower = c_mean - 0.5 * c_std
        v_upper = v_mean + 0.5 * v_std
        v_lower = v_mean - 0.5 * v_std

        clip_c = close.clip(lower=c_lower, upper=c_upper)
        clip_v = volume.clip(lower=v_lower, upper=v_upper)

        pv_corr_1m = clip_c.rolling(self.window, min_periods=self.min_corr).corr(clip_v)
        self.df["pv_corr"] = pv_corr_1m

        # 5-minute normalization (align with notebook)
        index_5m = close.resample("5min").last().dropna().index
        factor_5m = pv_corr_1m.reindex(index_5m)

        # STRICT per user's formula: use ewm(norm_window) positional arg (com)
        fast_ema = factor_5m.ewm(self.norm_window, min_periods=10).mean()
        slow_ema = factor_5m.ewm(8 * self.norm_window, min_periods=10).mean()
        slow_std = factor_5m.rolling(8 * self.norm_window, min_periods=10).std()

        # z = (fast - slow) / slow_std
        z = (fast_ema - slow_ema) / slow_std.replace(0, np.nan)

        # Store 5m dataframe for persistence/inspection
        self.df5 = pd.DataFrame(
            {
                "pv_corr": factor_5m,
                "fast_ema": fast_ema,
                "slow_ema": slow_ema,
                "slow_std": slow_std,
                "zscore": z,
            },
            index=index_5m,
        )

    def _persist(self):
        # ç›´æŽ¥ä½¿ç”¨è®¡ç®—å¥½çš„dfæˆ–ä»Žç¼“å†²æž„å»º
        if not self.buf:
            return
            
        df = getattr(self, "df", None) or self._build_df_from_buf()
        if df.empty:
            return

        # ä¿å­˜æœ€æ–°çš„ä¸€è¡Œæ•°æ®
        last_row = df.iloc[[-1]].copy()
        last_row.index.name = "ts"

        # é€‰æ‹©éœ€è¦ä¿å­˜çš„åˆ—
        available_cols = [c for c in ["o", "h", "l", "c", "vol", "amount", "pv_corr", "fast_ema", "slow_ema", "slow_std", "zscore"] if c in last_row.columns]
        last_row = last_row[available_cols]

        # è¿½åŠ ä¿å­˜åˆ°CSV
        header = not self._out_csv.exists()
        last_row.to_csv(self._out_csv, mode="a", header=header)

        # ä¿å­˜5åˆ†é’Ÿæ•°æ®ï¼ˆå¦‚æžœæœ‰æ–°çš„zscoreï¼‰
        df5 = getattr(self, "df5", None)
        if df5 is not None and not df5.empty:
            non_na = df5[~df5["zscore"].isna()]
            if not non_na.empty:
                last_5m_ts = non_na.index[-1]
                if self._last_5m_ts is None or last_5m_ts > self._last_5m_ts:
                    out_row_5m = non_na.iloc[[-1]].copy()
                    out_row_5m.index.name = "ts"
                    header5 = not self._out_csv_5m.exists()
                    out_row_5m.to_csv(self._out_csv_5m, mode="a", header=header5)
                    self._last_5m_ts = last_5m_ts


if __name__ == "__main__":
    eng = Engine(0.001)
    session = eng.make_session(
        addr="ws://localhost:8111", session_id=1, name="test", trading=True
    )

    depth = session.subscribe("dogeusdt", "depth")
    kline = session.subscribe("btcusdt", "kline:1m")
    demo = Demo(depth, kline)
    eng.run()
